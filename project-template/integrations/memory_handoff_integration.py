"""
Memory Handoff Integration Module

Purpose: Xiaoji's (å°æ†¶) automated memory handoff using compression mechanism
Version: 2.0.0 (Phase 1 - Universal Storage Integration)
Author: Claude Code + zycaskevin

Architecture: Hybrid Approach (Option D from XIAOJI_MEMORY_HANDOFF_DESIGN.md)
- Layer 1: Agent (xiaoji-memory-keeper.md) - Protocol definition
- Layer 2: Integration (this file) - Core orchestration
- Layer 3: Output Style - Minimal changes (triggers)
- Layer 4: Hook - Automatic triggers (optional)

Integration Strategy:
1. Detect trigger conditions (Token 70%, TODO completed, phase done)
2. Extract & compress context (using compress_context.py)
3. Enhance with Context7 + Exa (using existing integrations)
4. Store in Universal Memory (EvoMem or JSON fallback)
5. Generate handoff documents (HANDOFF_xxx.md, TODO_NEXT.md)

CHANGELOG v2.0.0:
- Integrated universal_memory_storage.py for flexible storage backends
- Support auto-degradation: EvoMem â†’ JSON
- Removed hardcoded JSON storage, now uses MemoryStorageFactory

Design Reference:
- XIAOJI_MEMORY_HANDOFF_DESIGN.md
- universal_memory_storage.py
"""

import json
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timezone

# Import existing compression and enhancement modules
try:
    # Add scripts and integrations to path
    scripts_dir = Path(__file__).parent.parent / "scripts"
    integrations_dir = Path(__file__).parent

    sys.path.insert(0, str(scripts_dir))
    sys.path.insert(0, str(integrations_dir))

    from compress_context import ContextCompressor, estimate_tokens
    from context7_integration import enhance_with_context7
    from exa_integration import enhance_with_exa

    # Import universal memory storage (v2.0.0)
    from universal_memory_storage import (
        MemoryStorageFactory,
        MemoryStorageInterface,
        StorageCapability
    )

    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    print(f"[WARNING] Dependencies not available: {e}")
    DEPENDENCIES_AVAILABLE = False


# ============================================================
# Trigger Detection (Step 1)
# ============================================================
class MemoryHandoffTrigger:
    """
    è‡ªå‹•åµæ¸¬è¨˜æ†¶äº¤æ¥è§¸ç™¼æ¢ä»¶

    è§¸ç™¼æ¢ä»¶:
    - Token ä½¿ç”¨é” 70%
    - å®Œæˆ 5 å€‹ TODO
    - éšæ®µå®Œæˆ (å¦‚ TDD Red/Green/Refactor)
    - ç¶“é 1 å°æ™‚
    - 3 æ¬¡ Git commit
    """

    # Default thresholds (å¯èª¿æ•´)
    TRIGGER_THRESHOLDS = {
        "token_usage": 0.70,        # 70% Token ä½¿ç”¨
        "todo_completed": 5,        # å®Œæˆ 5 å€‹ TODO
        "time_elapsed": 3600,       # 1 å°æ™‚ç¶“é (ç§’)
        "phase_completed": True,    # éšæ®µå®Œæˆ
        "git_commits": 3            # 3 æ¬¡ commit
    }

    def __init__(self, thresholds: Optional[Dict] = None):
        """
        Initialize trigger detector

        Args:
            thresholds: Custom thresholds (optional)
        """
        if thresholds:
            self.thresholds = {**self.TRIGGER_THRESHOLDS, **thresholds}
        else:
            self.thresholds = self.TRIGGER_THRESHOLDS

    def should_trigger_handoff(self, context: Dict) -> Tuple[bool, List[str]]:
        """
        åˆ¤æ–·æ˜¯å¦æ‡‰è©²è§¸ç™¼è¨˜æ†¶äº¤æ¥

        Args:
            context: {
                'current_tokens': int,
                'max_tokens': int,
                'todos': List[Dict],  # [{"status": "completed", "task": "..."}]
                'phase_completed': bool,
                'time_elapsed': Optional[int],
                'git_commits': Optional[int]
            }

        Returns:
            Tuple[bool, List[str]]: (should_trigger, reasons)
        """
        triggers = []

        # Check 1: Token ä½¿ç”¨ç‡
        current_tokens = context.get('current_tokens', 0)
        max_tokens = context.get('max_tokens', 200000)

        if max_tokens > 0:
            token_ratio = current_tokens / max_tokens
            if token_ratio >= self.thresholds['token_usage']:
                triggers.append(f'token_usage ({token_ratio:.1%})')

        # Check 2: TODO å®Œæˆæ•¸
        todos = context.get('todos', [])
        if todos:
            completed_count = len([t for t in todos if t.get('status') == 'completed'])
            if completed_count >= self.thresholds['todo_completed']:
                triggers.append(f'todo_completed ({completed_count})')

        # Check 3: éšæ®µå®Œæˆ
        if context.get('phase_completed'):
            triggers.append('phase_completed')

        # Check 4: æ™‚é–“ç¶“é
        time_elapsed = context.get('time_elapsed')
        if time_elapsed and time_elapsed >= self.thresholds['time_elapsed']:
            triggers.append(f'time_elapsed ({time_elapsed}s)')

        # Check 5: Git commits
        git_commits = context.get('git_commits')
        if git_commits and git_commits >= self.thresholds['git_commits']:
            triggers.append(f'git_commits ({git_commits})')

        # ä»»ä¸€è§¸ç™¼æ¢ä»¶æ»¿è¶³å³è§¸ç™¼
        should_trigger = len(triggers) > 0

        return should_trigger, triggers


# ============================================================
# Information Extraction (Step 2)
# ============================================================
class InformationExtractor:
    """
    å¾å°è©±ä¸­æå–é—œéµè³‡è¨Š

    æå–å…§å®¹:
    - Session intent, play-by-play, artifacts, breadcrumbs (via ContextCompressor)
    - TODOs (ç‹€æ…‹è¿½è¹¤)
    - Decisions (é—œéµæ±ºç­–)
    - Code patterns (ä»£ç¢¼æ¨¡å¼)
    - Learnings (å­¸ç¿’èˆ‡æ´å¯Ÿ)
    """

    def __init__(self):
        self.compressor = ContextCompressor()

    def extract(self, conversation: str, todos: List[Dict]) -> Dict:
        """
        æå–é—œéµè³‡è¨Šä¸¦å£“ç¸®

        Args:
            conversation: å®Œæ•´å°è©±å…§å®¹
            todos: TODO åˆ—è¡¨

        Returns:
            æå–çš„è³‡è¨Š (åŒ…å«å£“ç¸®çš„ä¸Šä¸‹æ–‡)
        """
        # ä½¿ç”¨ç¾æœ‰çš„å£“ç¸®å™¨
        compressed = self.compressor.compress(conversation)

        # é¡å¤–æå–
        extracted = {
            **compressed,
            "todos": todos,
            "decisions": self._extract_decisions(conversation),
            "code_patterns": self._extract_code_patterns(compressed['breadcrumbs']),
            "learnings": self._extract_learnings(compressed['playByPlay'])
        }

        return extracted

    def _extract_decisions(self, conversation: str) -> List[Dict]:
        """
        æå–é—œéµæ±ºç­–

        å°‹æ‰¾æ¨¡å¼:
        - "Decision:", "Decided to", "é¸æ“‡"
        - "Rationale:", "ç†ç”±", "å› ç‚º"
        """
        decisions = []

        # Simple extraction (å¯å¢å¼·ç‚º LLM-based)
        keywords = ['decision:', 'decided to', 'é¸æ“‡', 'rationale:', 'ç†ç”±']

        lines = conversation.split('\n')
        current_decision = None

        for line in lines:
            line_lower = line.lower()

            # Check for decision start
            if any(kw in line_lower for kw in ['decision:', 'decided to', 'é¸æ“‡']):
                if current_decision:
                    decisions.append(current_decision)

                current_decision = {
                    "decision": line.strip(),
                    "rationale": "",
                    "source": "conversation"
                }

            # Check for rationale
            elif current_decision and any(kw in line_lower for kw in ['rationale:', 'ç†ç”±', 'å› ç‚º']):
                current_decision["rationale"] = line.strip()

        # Add last decision
        if current_decision:
            decisions.append(current_decision)

        return decisions[:10]  # Limit to top 10

    def _extract_code_patterns(self, breadcrumbs: List[str]) -> List[Dict]:
        """
        å¾ breadcrumbs æå–ä»£ç¢¼æ¨¡å¼

        ä¾‹å¦‚:
        - function:sort_by_priority â†’ å„ªå…ˆç´šæ’åºæ¨¡å¼
        - class:MemoryHandoff â†’ è¨˜æ†¶äº¤æ¥æ¨¡å¼
        """
        patterns = []

        # Group by pattern type
        functions = [b for b in breadcrumbs if b.startswith('function:')]
        classes = [b for b in breadcrumbs if b.startswith('class:')]

        # Extract patterns (top 5)
        for func in functions[:5]:
            identifier = func.split(':', 1)[1]
            patterns.append({
                "pattern": identifier,
                "type": "function",
                "use_case": f"Function pattern: {identifier}"
            })

        for cls in classes[:5]:
            identifier = cls.split(':', 1)[1]
            patterns.append({
                "pattern": identifier,
                "type": "class",
                "use_case": f"Class pattern: {identifier}"
            })

        return patterns

    def _extract_learnings(self, play_by_play: List[str]) -> List[Dict]:
        """
        å¾ play-by-play æå–å­¸ç¿’èˆ‡æ´å¯Ÿ

        å°‹æ‰¾æ¨¡å¼:
        - "Fixed", "Optimized" â†’ è§£æ±ºæ–¹æ¡ˆ
        - "Implemented", "Created" â†’ æ–°åŠŸèƒ½
        """
        learnings = []

        # Keywords indicating learnings
        solution_keywords = ['fixed', 'resolved', 'solved', 'ä¿®å¾©']
        optimization_keywords = ['optimized', 'improved', 'å„ªåŒ–']
        implementation_keywords = ['implemented', 'created', 'å¯¦ä½œ', 'å‰µå»º']

        for action in play_by_play:
            action_lower = action.lower()

            # Solution learning
            if any(kw in action_lower for kw in solution_keywords):
                learnings.append({
                    "pattern": action,
                    "type": "solution",
                    "context": "Problem resolution"
                })

            # Optimization learning
            elif any(kw in action_lower for kw in optimization_keywords):
                learnings.append({
                    "pattern": action,
                    "type": "optimization",
                    "context": "Performance improvement"
                })

            # Implementation learning
            elif any(kw in action_lower for kw in implementation_keywords):
                learnings.append({
                    "pattern": action,
                    "type": "implementation",
                    "context": "New feature creation"
                })

        return learnings[:10]  # Limit to top 10


# ============================================================
# Enhancement (Step 3)
# ============================================================
class ContextEnhancer:
    """
    ä½¿ç”¨ Context7 + Exa å¢å¼·å£“ç¸®å…§å®¹
    """

    def enhance(self, compressed: Dict,
                use_context7: bool = True,
                use_exa: bool = True,
                context7_tokens: int = 500,
                exa_tokens: int = 300) -> Dict:
        """
        å¢å¼·å£“ç¸®å…§å®¹

        Args:
            compressed: å£“ç¸®çš„ä¸Šä¸‹æ–‡
            use_context7: å•Ÿç”¨ Context7
            use_exa: å•Ÿç”¨ Exa
            context7_tokens: Context7 Token é ç®—
            exa_tokens: Exa Token é ç®—

        Returns:
            å¢å¼·çš„ä¸Šä¸‹æ–‡
        """
        enhanced = compressed.copy()

        if not DEPENDENCIES_AVAILABLE:
            print("[WARNING] Enhancement dependencies not available")
            return enhanced

        # Step 3.1: Context7 æ–‡æª”å¢å¼·
        if use_context7:
            try:
                enhanced = enhance_with_context7(
                    enhanced,
                    use_mcp=False,  # ä½¿ç”¨ mock (æš«ä¸éœ€è¦çœŸå¯¦ MCP)
                    max_tokens=context7_tokens
                )
                print(f"  [OK] Context7: +{enhanced.get('enhancement', {}).get('total_tokens_added', 0)} tokens")
            except Exception as e:
                print(f"  [WARNING] Context7 enhancement failed: {e}")

        # Step 3.2: Exa æœ€ä½³å¯¦è¸å¢å¼·
        if use_exa:
            try:
                enhanced = enhance_with_exa(
                    enhanced,
                    use_api=False,  # ä½¿ç”¨ mock
                    max_tokens=exa_tokens
                )
                exa_added = enhanced.get('enhancement', {}).get('exa_tokens_added', 0)
                print(f"  [OK] Exa: +{exa_added} tokens")
            except Exception as e:
                print(f"  [WARNING] Exa enhancement failed: {e}")

        return enhanced


# ============================================================
# Storage (Step 4) - v2.0.0 Universal Storage Wrapper
# ============================================================
class MemoryStorage:
    """
    è¨˜æ†¶å­˜å„²åŒ…è£å™¨ï¼ˆv2.0.0 - Universal Storage Integrationï¼‰

    åŠŸèƒ½è®Šæ›´:
    - v1.0.0: ç¡¬ç·¨ç¢¼ JSON å­˜å„²
    - v2.0.0: ä½¿ç”¨ MemoryStorageFactory è‡ªå‹•æª¢æ¸¬å¾Œç«¯
      - å„ªå…ˆ: EvoMem (FULL capability - èªç¾©æœå°‹)
      - é™ç´š: JSON (BASIC capability - åŸºç¤å­˜å„²)

    é€™å€‹åŒ…è£å™¨ä¿æŒå‘å¾Œå…¼å®¹ï¼ŒåŒæ™‚æä¾›æ–°çš„é€šç”¨å­˜å„²èƒ½åŠ›ã€‚
    """

    def __init__(self, storage_config: Optional[Dict] = None):
        """
        Initialize storage with universal backend

        Args:
            storage_config: å­˜å„²é…ç½®ï¼ˆå¯é¸ï¼‰
                {
                    "type": "auto" | "evomem" | "json",
                    "evomem": {...},
                    "json": {"storage_dir": "data/memory"}
                }

                è‹¥æœªæä¾›ï¼Œä½¿ç”¨é›¶é…ç½®è‡ªå‹•æª¢æ¸¬
        """
        if storage_config is None:
            # Zero-config: Auto-detect with default JSON fallback dir
            storage_config = {
                "type": "auto",
                "json": {"storage_dir": "data/memory"}
            }

        # Create storage backend using factory
        self.backend: MemoryStorageInterface = MemoryStorageFactory.create(storage_config)

        # Log capability
        print(f"  [INFO] Memory storage initialized: {type(self.backend).__name__} "
              f"({self.backend.capability.value})")

    def store(self, memory_item: Dict) -> str:
        """
        å­˜å„²è¨˜æ†¶é …ç›®ï¼ˆä½¿ç”¨é€šç”¨å¾Œç«¯ï¼‰

        Args:
            memory_item: è¨˜æ†¶é …ç›®

        Returns:
            è¨˜æ†¶ ID

        Note:
            v2.0.0: è‡ªå‹•æª¢æ¸¬ memory_item['id']ï¼Œè‹¥ä¸å­˜åœ¨å‰‡ç”Ÿæˆ
        """
        # Generate memory ID if not present
        if 'id' not in memory_item:
            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            memory_item['id'] = f"mem_{timestamp}"

        # Store using backend
        memory_id = self.backend.store(memory_item)

        return memory_id

    def retrieve(self, memory_id: str) -> Optional[Dict]:
        """
        å–å›è¨˜æ†¶é …ç›®ï¼ˆä½¿ç”¨é€šç”¨å¾Œç«¯ï¼‰

        Args:
            memory_id: è¨˜æ†¶ ID

        Returns:
            è¨˜æ†¶é …ç›® or None
        """
        return self.backend.retrieve(memory_id)

    def search(self, query: str, **kwargs) -> List[Dict]:
        """
        èªç¾©æœå°‹è¨˜æ†¶ï¼ˆv2.0.0 æ–°åŠŸèƒ½ï¼‰

        Args:
            query: æœå°‹æŸ¥è©¢
            **kwargs: å¾Œç«¯ç‰¹å®šåƒæ•¸

        Returns:
            ç›¸é—œè¨˜æ†¶åˆ—è¡¨ï¼ˆè‹¥å¾Œç«¯ä¸æ”¯æ´ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼‰

        Note:
            åƒ… FULL capability å¾Œç«¯ï¼ˆå¦‚ EvoMemï¼‰æ”¯æ´æ­¤åŠŸèƒ½
            BASIC capability å¾Œç«¯ï¼ˆå¦‚ JSONï¼‰è¿”å›ç©ºåˆ—è¡¨
        """
        return self.backend.search(query, **kwargs)

    @property
    def capability(self) -> StorageCapability:
        """
        å–å¾—ç•¶å‰å­˜å„²å¾Œç«¯çš„èƒ½åŠ›ç­‰ç´š

        Returns:
            StorageCapability: FULL or BASIC
        """
        return self.backend.capability


# ============================================================
# Documentation (Step 5)
# ============================================================
class HandoffDocumenter:
    """
    ç”Ÿæˆäººé¡å¯è®€çš„äº¤æ¥æ–‡æª”
    """

    def generate_handoff(self, memory_item: Dict,
                        output_dir: str = ".") -> str:
        """
        ç”Ÿæˆäº¤æ¥æ–‡æª”

        Args:
            memory_item: è¨˜æ†¶é …ç›®
            output_dir: è¼¸å‡ºç›®éŒ„

        Returns:
            æ–‡æª”æª”å
        """
        # Generate filename
        phase = memory_item.get('metadata', {}).get('phase', 'unknown')
        timestamp = datetime.now().strftime("%Y%m%d")
        filename = f"HANDOFF_{phase}_{timestamp}.md"

        # Generate content
        doc_content = self._format_handoff_document(memory_item)

        # Write file
        filepath = Path(output_dir) / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(doc_content)

        print(f"  [OK] Handoff doc: {filepath}")

        return filename

    def generate_todo_next(self, memory_item: Dict,
                          output_dir: str = ".") -> str:
        """
        ç”Ÿæˆä¸‹ä¸€æ­¥ TODO æ–‡æª”

        Args:
            memory_item: è¨˜æ†¶é …ç›®
            output_dir: è¼¸å‡ºç›®éŒ„

        Returns:
            æ–‡æª”æª”å
        """
        filename = "TODO_NEXT.md"

        # Extract pending TODOs
        todos = memory_item.get('session_memory', {}).get('todos', [])
        pending_todos = [t for t in todos if t.get('status') == 'pending']

        # Generate content
        doc_content = f"""# ä¸‹ä¸€æ­¥ TODO

**ç”Ÿæˆæ™‚é–“**: {datetime.now(timezone.utc).isoformat()}
**å°ˆæ¡ˆ**: {memory_item.get('metadata', {}).get('project', 'Unknown')}
**éšæ®µ**: {memory_item.get('metadata', {}).get('phase', 'Unknown')}

---

## ğŸ”„ å¾…è¾¦äº‹é …

"""

        for i, todo in enumerate(pending_todos, 1):
            doc_content += f"{i}. **{todo.get('task', 'Unknown task')}**\n"
            if 'activeForm' in todo:
                doc_content += f"   - é€²è¡Œä¸­: {todo['activeForm']}\n"
            doc_content += "\n"

        if not pending_todos:
            doc_content += "âœ… ç„¡å¾…è¾¦äº‹é …\n\n"

        doc_content += f"""---

*è‡ªå‹•ç”Ÿæˆæ–¼ {datetime.now(timezone.utc).isoformat()} by å°æ†¶ (Memory Keeper)*
"""

        # Write file
        filepath = Path(output_dir) / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(doc_content)

        print(f"  [OK] TODO doc: {filepath}")

        return filename

    def _format_handoff_document(self, memory_item: Dict) -> str:
        """æ ¼å¼åŒ–äº¤æ¥æ–‡æª”"""

        session = memory_item.get('session_memory', {})
        longterm = memory_item.get('long_term_memory', {})
        metadata = memory_item.get('metadata', {})

        doc = f"""# è¨˜æ†¶äº¤æ¥æ–‡æª”

**æ™‚é–“**: {memory_item.get('timestamp', 'Unknown')}
**è¨˜æ†¶ ID**: {memory_item.get('id', 'Unknown')}
**å°ˆæ¡ˆ**: {metadata.get('project', 'Unknown')}
**éšæ®µ**: {metadata.get('phase', 'Unknown')}

---

## ğŸ“‹ ä»»å‹™æ‘˜è¦

**ä»»å‹™ç›®æ¨™**:
"""

        for intent in session.get('sessionIntent', []):
            doc += f"- {intent}\n"

        doc += "\n**å®Œæˆäº‹é …**:\n"
        for action in session.get('playByPlay', []):
            doc += f"- âœ… {action}\n"

        doc += "\n---\n\n## ğŸ“ ç”¢å‡ºç‰©\n\n**æª”æ¡ˆ**:\n"
        for artifact in session.get('artifacts', []):
            doc += f"- [{artifact}]({artifact})\n"

        doc += "\n---\n\n## ğŸ”‘ é—œéµæ±ºç­–\n\n"
        for decision in session.get('decisions', []):
            doc += f"**æ±ºç­–**: {decision.get('decision', 'Unknown')}\n"
            doc += f"- **ç†ç”±**: {decision.get('rationale', 'N/A')}\n"
            doc += f"- **ä¾†æº**: {decision.get('source', 'N/A')}\n\n"

        doc += "---\n\n## ğŸ’¡ å­¸ç¿’èˆ‡æ´å¯Ÿ\n\n"
        for learning in longterm.get('learnings', []):
            doc += f"**æ¨¡å¼**: {learning.get('pattern', 'Unknown')}\n"
            doc += f"- **é¡å‹**: {learning.get('type', 'N/A')}\n"
            doc += f"- **æƒ…å¢ƒ**: {learning.get('context', 'N/A')}\n\n"

        doc += f"""---

## ğŸ“Š æ•ˆèƒ½æŒ‡æ¨™

- **Token å£“ç¸®**: {metadata.get('token_before', 0):,} â†’ {metadata.get('token_after', 0):,} ({metadata.get('compression_ratio', 0) * 100:.1f}% å£“ç¸®)
- **å“è³ªè©•åˆ†**: {metadata.get('quality_score', 0)}/10

---

*è‡ªå‹•ç”Ÿæˆæ–¼ {memory_item.get('timestamp', 'Unknown')} by å°æ†¶ (Memory Keeper)*
"""

        return doc


# ============================================================
# Main Orchestrator
# ============================================================
class MemoryHandoffOrchestrator:
    """
    å°æ†¶çš„è¨˜æ†¶äº¤æ¥ç·¨æ’å™¨

    åŸ·è¡Œå®Œæ•´çš„ 5-Step æµç¨‹:
    1. æª¢æŸ¥è§¸ç™¼æ¢ä»¶
    2. æå–é—œéµè³‡è¨Šä¸¦å£“ç¸®
    3. ä½¿ç”¨ Context7 + Exa å¢å¼·
    4. å­˜å…¥è¨˜æ†¶å­˜å„²
    5. ç”Ÿæˆäº¤æ¥æ–‡æª”
    """

    def __init__(self,
                 storage_dir: str = "data/memory",
                 output_dir: str = "."):
        """
        Initialize orchestrator

        Args:
            storage_dir: è¨˜æ†¶å­˜å„²ç›®éŒ„
            output_dir: æ–‡æª”è¼¸å‡ºç›®éŒ„
        """
        self.trigger = MemoryHandoffTrigger()
        self.extractor = InformationExtractor()
        self.enhancer = ContextEnhancer()
        self.storage = MemoryStorage(storage_dir)
        self.documenter = HandoffDocumenter()
        self.output_dir = output_dir

    def execute_handoff(self,
                       conversation: str,
                       current_tokens: int,
                       max_tokens: int,
                       todos: List[Dict],
                       metadata: Optional[Dict] = None) -> Dict:
        """
        åŸ·è¡Œå®Œæ•´çš„è¨˜æ†¶äº¤æ¥æµç¨‹

        Args:
            conversation: å®Œæ•´å°è©±å…§å®¹
            current_tokens: ç•¶å‰ Token ä½¿ç”¨
            max_tokens: æœ€å¤§ Token é™åˆ¶
            todos: TODO åˆ—è¡¨ [{"status": "completed", "task": "..."}]
            metadata: é¡å¤– metadata (project, phase, etc.)

        Returns:
            {
                "success": bool,
                "compressed": Dict,
                "enhanced": Dict,
                "memory_id": str,
                "handoff_doc": str,
                "todo_next": str,
                "compression_ratio": float
            }
        """
        if metadata is None:
            metadata = {}

        print("\n[Xiaoji] å°æ†¶: é–‹å§‹è¨˜æ†¶äº¤æ¥æµç¨‹...")
        print("=" * 60)

        # Step 1: æª¢æŸ¥è§¸ç™¼æ¢ä»¶
        print("\n[Step 1/5] æª¢æŸ¥è§¸ç™¼æ¢ä»¶...")

        should_trigger, reasons = self.trigger.should_trigger_handoff({
            'current_tokens': current_tokens,
            'max_tokens': max_tokens,
            'todos': todos,
            'phase_completed': metadata.get('phase_completed', False)
        })

        if not should_trigger:
            print("  [INFO] æœªé”è§¸ç™¼æ¢ä»¶")
            return {
                "success": False,
                "reason": "No trigger conditions met"
            }

        print(f"  [OK] è§¸ç™¼åŸå› : {', '.join(reasons)}")

        # Step 2: æå– & å£“ç¸®
        print("\n[Step 2/5] æå–é—œéµè³‡è¨Šä¸¦å£“ç¸®...")
        compressed = self.extractor.extract(conversation, todos)

        token_before = current_tokens
        token_after = compressed['compressionMetadata']['compressedTokens']
        compression_ratio = compressed['compressionMetadata']['compressionRate']

        print(f"  [OK] å£“ç¸®: {token_before:,} -> {token_after:,} tokens ({compression_ratio * 100:.1f}%)")

        # Step 3: å¢å¼·æœå°‹
        print("\n[Step 3/5] ä½¿ç”¨ Context7 + Exa å¢å¼·...")
        enhanced = self.enhancer.enhance(compressed)

        # Step 4: å­˜å…¥è¨˜æ†¶
        print("\n[Step 4/5] å­˜å…¥è¨˜æ†¶å­˜å„²...")

        memory_item = self._build_memory_item(
            compressed, enhanced, metadata,
            token_before, token_after, compression_ratio
        )

        memory_id = self.storage.store(memory_item)

        # Step 5: ç”Ÿæˆæ–‡æª”
        print("\n[Step 5/5] ç”Ÿæˆäº¤æ¥æ–‡æª”...")
        handoff_doc = self.documenter.generate_handoff(memory_item, self.output_dir)
        todo_next = self.documenter.generate_todo_next(memory_item, self.output_dir)

        # Summary
        print("\n" + "=" * 60)
        print("[SUCCESS] è¨˜æ†¶äº¤æ¥å®Œæˆ!")
        print(f"   - å£“ç¸®ç‡: {compression_ratio * 100:.1f}%")
        print(f"   - è¨˜æ†¶ ID: {memory_id}")
        print(f"   - äº¤æ¥æ–‡æª”: {handoff_doc}")
        print(f"   - TODO æ–‡æª”: {todo_next}")
        print("=" * 60)

        return {
            "success": True,
            "compressed": compressed,
            "enhanced": enhanced,
            "memory_id": memory_id,
            "handoff_doc": handoff_doc,
            "todo_next": todo_next,
            "compression_ratio": compression_ratio,
            "token_before": token_before,
            "token_after": token_after
        }

    def _build_memory_item(self, compressed: Dict, enhanced: Dict,
                          metadata: Dict,
                          token_before: int, token_after: int,
                          compression_ratio: float) -> Dict:
        """æ§‹å»ºè¨˜æ†¶é …ç›®"""

        return {
            "type": "handoff",
            "timestamp": datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z'),
            "from_agent": "general",
            "to_agent": "xiaoji",

            "session_memory": {
                "sessionIntent": compressed.get('sessionIntent', []),
                "playByPlay": compressed.get('playByPlay', []),
                "artifacts": compressed.get('artifacts', []),
                "breadcrumbs": compressed.get('breadcrumbs', []),
                "todos": compressed.get('todos', []),
                "decisions": compressed.get('decisions', [])
            },

            "long_term_memory": {
                "learnings": compressed.get('learnings', []),
                "best_practices": [],
                "code_patterns": compressed.get('code_patterns', [])
            },

            "enhancements": {
                "context7_docs": enhanced.get('enhancement', {}).get('context7_docs', []),
                "exa_search": enhanced.get('enhancement', {}).get('exa_search', [])
            },

            "metadata": {
                "project": metadata.get('project', 'Unknown'),
                "phase": metadata.get('phase', 'Unknown'),
                "token_before": token_before,
                "token_after": token_after,
                "compression_ratio": compression_ratio,
                "quality_score": 9.0  # TODO: å¯¦ä½œå“è³ªè©•ä¼°
            }
        }


# ============================================================
# CLI Interface (for testing)
# ============================================================
def main():
    """Test the memory handoff system"""
    print("Memory Handoff Integration - Test")
    print("=" * 60)

    # Test conversation
    test_conversation = """
User: å¯¦ä½œ P1-4.2 ä¸‰å¤§åŠŸèƒ½
Assistant: é–‹å§‹å¯¦ä½œæ¡†æ¶å„ªå…ˆç´šæ¬Šé‡ç³»çµ±...
Created: context7_integration.py
Implemented: sort_libraries_by_priority function
Implemented: extract_version_from_breadcrumbs function
Implemented: enrich_libraries_with_dependencies function

Decision: ä½¿ç”¨ 5 å±¤æ¬Šé‡ç³»çµ± (10/7-8/5-6/3/1)
Rationale: å¹³è¡¡é‡è¦æ€§èˆ‡éˆæ´»æ€§

Fixed: Version detection regex pattern
Optimized: Token allocation by priority

Created: test_p1_4_2_features.py
All tests passed (3/3)
"""

    # Test TODOs
    test_todos = [
        {"status": "completed", "task": "å¯¦ä½œå„ªå…ˆç´šç³»çµ±", "activeForm": "å¯¦ä½œå„ªå…ˆç´šç³»çµ±"},
        {"status": "completed", "task": "å¯¦ä½œç‰ˆæœ¬åµæ¸¬", "activeForm": "å¯¦ä½œç‰ˆæœ¬åµæ¸¬"},
        {"status": "completed", "task": "å¯¦ä½œä¾è³´é—œä¿‚", "activeForm": "å¯¦ä½œä¾è³´é—œä¿‚"},
        {"status": "completed", "task": "æ’°å¯«æ¸¬è©¦", "activeForm": "æ’°å¯«æ¸¬è©¦"},
        {"status": "completed", "task": "åŸ·è¡Œæ¸¬è©¦", "activeForm": "åŸ·è¡Œæ¸¬è©¦"},
        {"status": "pending", "task": "å¯¦ä½œ P1-5 å„ªåŒ–", "activeForm": "å¯¦ä½œ P1-5 å„ªåŒ–"}
    ]

    # Test metadata
    test_metadata = {
        "project": "å°ˆæ¡ˆå•Ÿå‹•æ–‡æª”å°ˆæ¡ˆ",
        "phase": "P1-4.2",
        "phase_completed": True
    }

    # Execute handoff
    orchestrator = MemoryHandoffOrchestrator(
        storage_dir="data/memory",
        output_dir="."
    )

    result = orchestrator.execute_handoff(
        conversation=test_conversation,
        current_tokens=145000,
        max_tokens=200000,
        todos=test_todos,
        metadata=test_metadata
    )

    if result['success']:
        print("\n[SUCCESS] Memory handoff completed successfully!")
    else:
        print(f"\n[FAIL] Memory handoff failed: {result.get('reason', 'Unknown')}")


if __name__ == "__main__":
    if not DEPENDENCIES_AVAILABLE:
        print("[ERROR] Dependencies not available. Cannot run test.")
        print("  Required: compress_context.py, context7_integration.py, exa_integration.py")
        sys.exit(1)

    main()
